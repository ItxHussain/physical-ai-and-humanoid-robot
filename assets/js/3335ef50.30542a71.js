"use strict";(globalThis.webpackChunkphysical_ai_and_humanoid_robot=globalThis.webpackChunkphysical_ai_and_humanoid_robot||[]).push([[695],{8453:(e,i,n)=>{n.d(i,{R:()=>r,x:()=>l});var s=n(6540);const o={},t=s.createContext(o);function r(e){const i=s.useContext(t);return s.useMemo(function(){return"function"==typeof e?e(i):{...i,...e}},[i,e])}function l(e){let i;return i=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:r(e.components),s.createElement(t.Provider,{value:i},e.children)}},9917:(e,i,n)=>{n.r(i),n.d(i,{assets:()=>a,contentTitle:()=>l,default:()=>h,frontMatter:()=>r,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"physical-ai-modules/module-1-ros2","title":"Module 1: ROS 2 (Robotic Nervous System)","description":"Overview","source":"@site/docs/physical-ai-modules/module-1-ros2.md","sourceDirName":"physical-ai-modules","slug":"/physical-ai-modules/module-1-ros2","permalink":"/physical-ai-and-humanoid-robot/docs/physical-ai-modules/module-1-ros2","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/physical-ai-modules/module-1-ros2.md","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2},"sidebar":"tutorialSidebar","previous":{"title":"Physical AI Modules Book","permalink":"/physical-ai-and-humanoid-robot/docs/physical-ai-modules/"},"next":{"title":"Module 2: Digital Twin (Gazebo & Unity)","permalink":"/physical-ai-and-humanoid-robot/docs/physical-ai-modules/module-2-digital-twin"}}');var o=n(4848),t=n(8453);const r={sidebar_position:2},l="Module 1: ROS 2 (Robotic Nervous System)",a={},c=[{value:"Overview",id:"overview",level:2},{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"1. ROS 2 Architecture",id:"1-ros-2-architecture",level:2},{value:"Key Components:",id:"key-components",level:3},{value:"2. Nodes, Topics, Services, and Actions",id:"2-nodes-topics-services-and-actions",level:2},{value:"Nodes",id:"nodes",level:3},{value:"Topics",id:"topics",level:3},{value:"Services",id:"services",level:3},{value:"Actions",id:"actions",level:3},{value:"3. Bridging Python Agents with rclpy",id:"3-bridging-python-agents-with-rclpy",level:2},{value:"4. URDF for Humanoid Modeling",id:"4-urdf-for-humanoid-modeling",level:2},{value:"Kinematic Structure",id:"kinematic-structure",level:3},{value:"Visual and Collision Properties",id:"visual-and-collision-properties",level:3},{value:"Inertial Properties",id:"inertial-properties",level:3},{value:"Joint Constraints",id:"joint-constraints",level:3},{value:"URDF Best Practices for Humanoid Robots",id:"urdf-best-practices-for-humanoid-robots",level:3},{value:"5. Practical Applications",id:"5-practical-applications",level:2},{value:"Boston Dynamics Spot Robots",id:"boston-dynamics-spot-robots",level:3},{value:"NASA&#39;s Robonaut 2",id:"nasas-robonaut-2",level:3},{value:"Toyota HSR (Human Support Robot)",id:"toyota-hsr-human-support-robot",level:3},{value:"Summary",id:"summary",level:2},{value:"Key Takeaways",id:"key-takeaways",level:3},{value:"Integration Points",id:"integration-points",level:3},{value:"References",id:"references",level:2}];function d(e){const i={code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,t.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(i.header,{children:(0,o.jsx)(i.h1,{id:"module-1-ros-2-robotic-nervous-system",children:"Module 1: ROS 2 (Robotic Nervous System)"})}),"\n",(0,o.jsx)(i.h2,{id:"overview",children:"Overview"}),"\n",(0,o.jsx)(i.p,{children:"Robot Operating System 2 (ROS 2) serves as the nervous system for humanoid robots, providing the middleware infrastructure that enables communication between different software components. This module covers the essential aspects of ROS 2 that enable humanoid robot functionality."}),"\n",(0,o.jsx)(i.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,o.jsx)(i.p,{children:"After completing this module, you will be able to:"}),"\n",(0,o.jsxs)(i.ul,{children:["\n",(0,o.jsx)(i.li,{children:"Understand the core concepts of ROS 2 architecture"}),"\n",(0,o.jsx)(i.li,{children:"Explain the role of nodes, topics, services, and actions in robot communication"}),"\n",(0,o.jsx)(i.li,{children:"Describe how ROS 2 enables bridging between Python agents and robot hardware"}),"\n",(0,o.jsx)(i.li,{children:"Understand URDF's role in humanoid modeling"}),"\n"]}),"\n",(0,o.jsx)(i.h2,{id:"1-ros-2-architecture",children:"1. ROS 2 Architecture"}),"\n",(0,o.jsx)(i.p,{children:"ROS 2 is a flexible framework for writing robot software that provides a collection of libraries and tools to help software developers create robot applications. It uses a distributed architecture where multiple processes (potentially on different machines) can communicate with each other."}),"\n",(0,o.jsx)(i.h3,{id:"key-components",children:"Key Components:"}),"\n",(0,o.jsxs)(i.ul,{children:["\n",(0,o.jsxs)(i.li,{children:[(0,o.jsx)(i.strong,{children:"Nodes"}),": Processes that perform computation"]}),"\n",(0,o.jsxs)(i.li,{children:[(0,o.jsx)(i.strong,{children:"Topics"}),": Named buses over which nodes exchange messages"]}),"\n",(0,o.jsxs)(i.li,{children:[(0,o.jsx)(i.strong,{children:"Services"}),": Synchronous request/response communication"]}),"\n",(0,o.jsxs)(i.li,{children:[(0,o.jsx)(i.strong,{children:"Actions"}),": Asynchronous goal-oriented communication"]}),"\n"]}),"\n",(0,o.jsx)(i.h2,{id:"2-nodes-topics-services-and-actions",children:"2. Nodes, Topics, Services, and Actions"}),"\n",(0,o.jsx)(i.h3,{id:"nodes",children:"Nodes"}),"\n",(0,o.jsx)(i.p,{children:"Nodes are the fundamental building blocks of a ROS 2 system. Each node is a process that performs a specific task and communicates with other nodes through topics, services, or actions."}),"\n",(0,o.jsx)(i.h3,{id:"topics",children:"Topics"}),"\n",(0,o.jsx)(i.p,{children:"Topics enable asynchronous communication through a publish/subscribe model. Publishers send messages to topics, and subscribers receive messages from topics."}),"\n",(0,o.jsx)(i.h3,{id:"services",children:"Services"}),"\n",(0,o.jsx)(i.p,{children:"Services provide synchronous request/response communication. A client sends a request to a service, and the service returns a response."}),"\n",(0,o.jsx)(i.h3,{id:"actions",children:"Actions"}),"\n",(0,o.jsx)(i.p,{children:"Actions are used for long-running tasks that may need to be preempted or provide feedback during execution."}),"\n",(0,o.jsx)(i.h2,{id:"3-bridging-python-agents-with-rclpy",children:"3. Bridging Python Agents with rclpy"}),"\n",(0,o.jsx)(i.p,{children:"The Python client library for ROS 2 (rclpy) allows Python-based AI agents to interface with the ROS 2 ecosystem. This enables high-level cognitive functions to control robot behaviors."}),"\n",(0,o.jsx)(i.pre,{children:(0,o.jsx)(i.code,{className:"language-python",children:"import rclpy\nfrom rclpy.node import Node\n\nclass HumanoidController(Node):\n    def __init__(self):\n        super().__init__('humanoid_controller')\n        # Initialize publishers, subscribers, and services\n"})}),"\n",(0,o.jsx)(i.h2,{id:"4-urdf-for-humanoid-modeling",children:"4. URDF for Humanoid Modeling"}),"\n",(0,o.jsx)(i.p,{children:"Unified Robot Description Format (URDF) is an XML format for representing a robot model. For humanoid robots, URDF defines:"}),"\n",(0,o.jsx)(i.h3,{id:"kinematic-structure",children:"Kinematic Structure"}),"\n",(0,o.jsxs)(i.ul,{children:["\n",(0,o.jsx)(i.li,{children:"Joint types (revolute, prismatic, fixed, etc.)"}),"\n",(0,o.jsx)(i.li,{children:"Link connections and parent-child relationships"}),"\n",(0,o.jsx)(i.li,{children:"Degrees of freedom for each limb"}),"\n",(0,o.jsx)(i.li,{children:"Forward and inverse kinematics definitions"}),"\n",(0,o.jsx)(i.li,{children:"Kinematic chains for arms, legs, and torso"}),"\n"]}),"\n",(0,o.jsx)(i.h3,{id:"visual-and-collision-properties",children:"Visual and Collision Properties"}),"\n",(0,o.jsxs)(i.ul,{children:["\n",(0,o.jsx)(i.li,{children:"Mesh files for 3D visualization"}),"\n",(0,o.jsx)(i.li,{children:"Color and material properties"}),"\n",(0,o.jsx)(i.li,{children:"Collision geometry definitions"}),"\n",(0,o.jsx)(i.li,{children:"Sensor mounting points"}),"\n",(0,o.jsx)(i.li,{children:"Physical appearance parameters"}),"\n"]}),"\n",(0,o.jsx)(i.h3,{id:"inertial-properties",children:"Inertial Properties"}),"\n",(0,o.jsxs)(i.ul,{children:["\n",(0,o.jsx)(i.li,{children:"Mass distribution for each link"}),"\n",(0,o.jsx)(i.li,{children:"Center of mass locations"}),"\n",(0,o.jsx)(i.li,{children:"Inertia tensor values"}),"\n",(0,o.jsx)(i.li,{children:"Gravitational force calculations"}),"\n",(0,o.jsx)(i.li,{children:"Dynamic simulation parameters"}),"\n"]}),"\n",(0,o.jsx)(i.h3,{id:"joint-constraints",children:"Joint Constraints"}),"\n",(0,o.jsxs)(i.ul,{children:["\n",(0,o.jsx)(i.li,{children:"Position limits and ranges of motion"}),"\n",(0,o.jsx)(i.li,{children:"Velocity and acceleration limits"}),"\n",(0,o.jsx)(i.li,{children:"Effort/torque constraints"}),"\n",(0,o.jsx)(i.li,{children:"Safety boundaries for movement"}),"\n",(0,o.jsx)(i.li,{children:"Hardware-specific limitations"}),"\n"]}),"\n",(0,o.jsx)(i.h3,{id:"urdf-best-practices-for-humanoid-robots",children:"URDF Best Practices for Humanoid Robots"}),"\n",(0,o.jsxs)(i.ul,{children:["\n",(0,o.jsx)(i.li,{children:"Modular design for easy modification"}),"\n",(0,o.jsx)(i.li,{children:"Proper scaling and dimensional accuracy"}),"\n",(0,o.jsx)(i.li,{children:"Consistent naming conventions"}),"\n",(0,o.jsx)(i.li,{children:"Integration with ROS 2 control frameworks"}),"\n",(0,o.jsx)(i.li,{children:"Compatibility with simulation environments"}),"\n"]}),"\n",(0,o.jsx)(i.p,{children:"URDF serves as the foundational representation that enables ROS 2 to understand the physical structure of humanoid robots, making it possible to implement complex control algorithms, motion planning, and simulation scenarios."}),"\n",(0,o.jsx)(i.h2,{id:"5-practical-applications",children:"5. Practical Applications"}),"\n",(0,o.jsx)(i.p,{children:"ROS 2 is used in numerous humanoid robotics applications including:"}),"\n",(0,o.jsx)(i.h3,{id:"boston-dynamics-spot-robots",children:"Boston Dynamics Spot Robots"}),"\n",(0,o.jsxs)(i.ul,{children:["\n",(0,o.jsx)(i.li,{children:"Multi-robot coordination using ROS 2 middleware"}),"\n",(0,o.jsx)(i.li,{children:"Real-time sensor data processing and control"}),"\n",(0,o.jsx)(i.li,{children:"Integration with perception and navigation systems"}),"\n"]}),"\n",(0,o.jsx)(i.h3,{id:"nasas-robonaut-2",children:"NASA's Robonaut 2"}),"\n",(0,o.jsxs)(i.ul,{children:["\n",(0,o.jsx)(i.li,{children:"Humanoid robot control for space operations"}),"\n",(0,o.jsx)(i.li,{children:"Safety-critical communication protocols"}),"\n",(0,o.jsx)(i.li,{children:"Human-robot collaboration interfaces"}),"\n"]}),"\n",(0,o.jsx)(i.h3,{id:"toyota-hsr-human-support-robot",children:"Toyota HSR (Human Support Robot)"}),"\n",(0,o.jsxs)(i.ul,{children:["\n",(0,o.jsx)(i.li,{children:"Service robot for elderly care"}),"\n",(0,o.jsx)(i.li,{children:"Task planning and execution coordination"}),"\n",(0,o.jsx)(i.li,{children:"Human interaction and communication"}),"\n"]}),"\n",(0,o.jsx)(i.p,{children:"These applications demonstrate how ROS 2 serves as the essential communication backbone that enables complex humanoid robot behaviors and coordination."}),"\n",(0,o.jsx)(i.h2,{id:"summary",children:"Summary"}),"\n",(0,o.jsx)(i.p,{children:"ROS 2 serves as the essential middleware that connects all components of a humanoid robot system. Its distributed architecture allows for modular development and robust communication between different robot subsystems."}),"\n",(0,o.jsx)(i.h3,{id:"key-takeaways",children:"Key Takeaways"}),"\n",(0,o.jsxs)(i.ul,{children:["\n",(0,o.jsx)(i.li,{children:"ROS 2 provides the foundational communication infrastructure for humanoid robots"}),"\n",(0,o.jsx)(i.li,{children:"The publish/subscribe model enables asynchronous communication between robot components"}),"\n",(0,o.jsx)(i.li,{children:"Services and actions facilitate synchronous and goal-oriented communication patterns"}),"\n",(0,o.jsx)(i.li,{children:"The rclpy library bridges Python-based AI agents with the ROS 2 ecosystem"}),"\n",(0,o.jsx)(i.li,{children:"URDF provides the essential robot description that enables control and simulation"}),"\n",(0,o.jsx)(i.li,{children:"The distributed architecture supports both single-robot and multi-robot systems"}),"\n",(0,o.jsx)(i.li,{children:"Safety protocols and real-time capabilities make ROS 2 suitable for humanoid applications"}),"\n"]}),"\n",(0,o.jsx)(i.h3,{id:"integration-points",children:"Integration Points"}),"\n",(0,o.jsx)(i.p,{children:"ROS 2 connects seamlessly with the other Physical AI modules:"}),"\n",(0,o.jsxs)(i.ul,{children:["\n",(0,o.jsx)(i.li,{children:"Digital Twin simulations use ROS 2 interfaces for communication"}),"\n",(0,o.jsx)(i.li,{children:"NVIDIA Isaac systems integrate through ROS 2 middleware"}),"\n",(0,o.jsx)(i.li,{children:"VLA systems communicate through ROS 2 topics and services"}),"\n",(0,o.jsx)(i.li,{children:"This interconnected architecture enables the perception \u2192 planning \u2192 navigation \u2192 manipulation pipeline"}),"\n"]}),"\n",(0,o.jsx)(i.p,{children:"The robustness, flexibility, and extensive tooling of ROS 2 make it the nervous system of modern humanoid robots, enabling complex behaviors through reliable inter-component communication."}),"\n",(0,o.jsx)(i.h2,{id:"references",children:"References"}),"\n",(0,o.jsxs)(i.ol,{children:["\n",(0,o.jsxs)(i.li,{children:["Quigley, M., Conley, K., & Gerkey, B. P. (2009). ROS: an open-source robot operating system. ",(0,o.jsx)(i.em,{children:"ICRA Workshop on Open Source Software"}),", 3(3.2), 5."]}),"\n",(0,o.jsxs)(i.li,{children:["Macenski, S., Woodall, W., & Faust, A. (2022). ROS 2 design overview. ",(0,o.jsx)(i.em,{children:"arXiv preprint arXiv:2201.01810"}),"."]}),"\n",(0,o.jsxs)(i.li,{children:["Colom\xe9, A., & Torras, C. (2019). Robot operating system (ROS): advanced concepts. ",(0,o.jsx)(i.em,{children:"Springer International Publishing"}),"."]}),"\n",(0,o.jsxs)(i.li,{children:["Chen, L., et al. (2021). A comprehensive survey of ROS-based mobile manipulation platforms. ",(0,o.jsx)(i.em,{children:"IEEE Access"}),", 9, 103511-103526."]}),"\n",(0,o.jsxs)(i.li,{children:["L\xfctkebohle, I., et al. (2012). Robot state publishing with ROS. ",(0,o.jsx)(i.em,{children:"IEEE Robotics & Automation Magazine"}),", 19(4), 62-65."]}),"\n"]})]})}function h(e={}){const{wrapper:i}={...(0,t.R)(),...e.components};return i?(0,o.jsx)(i,{...e,children:(0,o.jsx)(d,{...e})}):d(e)}}}]);